{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Adds 'src' to the module search path\n",
    "sys.path.append(os.path.abspath(\"../src\"))  # Adds 'src' to the module search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e1a72a-3eb9-469c-8791-38d6dcacd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import create_model_dataset\n",
    "from read_data import apply_index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d8c432-728e-4443-868f-bc4b32419149",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "RAW_DATASET = \"../raw_data/massive.parquet\"\n",
    "DATA = \"../data/\"\n",
    "TRAIN = \"../data/train_subsets/\"\n",
    "TEST = \"../data/test/\"\n",
    "os.makedirs(DATA, exist_ok=True)\n",
    "os.makedirs(TRAIN, exist_ok=True)\n",
    "os.makedirs(TEST, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b53617-3a20-479e-9a05-2df1472cd549",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360cd88b-e8e9-41cc-8529-52e535e92cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_dataset(RAW_DATASET,f\"{DATA}dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fd43e-27ab-4f05-a75b-ca5b7ed8be9b",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ce4a8b-a098-46fd-8394-e3ec15c8350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006c5f0d-5f5c-47b7-9dc9-8d0014c68b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dataset = df.groupby('dataset')['modified_sequence'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7815be13-ad1f-4bb9-a1b7-99bbe747b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = df['dataset'].unique()\n",
    "test_datasets = ['MSV000080274']\n",
    "val_datasets = ['MSV000079550']\n",
    "train_datasets = [d for d in all_datasets if d not in test_datasets + val_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57933ac-f3a5-468a-99a4-9aac12579b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['dataset'].isin(test_datasets)].sample(350000, random_state=42) \n",
    "val_df = df[df['dataset'].isin(val_datasets)].sample(350000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a848c00-e3ff-469b-aa86-423411156036",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_with_intersection = set(test_df['modified_sequence'])\n",
    "val_sequences_with_intersection = set(val_df['modified_sequence'])\n",
    "common_sequences = test_sequences_with_intersection.intersection(val_sequences_with_intersection)\n",
    "common_sequences_list = list(common_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e4a5b18-fc9c-4516-9609-57253983c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset size: 242478\n",
      "validation dataset size: 251021\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(common_sequences_list)\n",
    "half_point = len(common_sequences_list) // 2\n",
    "test_keep_sequences = set(common_sequences_list[:half_point])\n",
    "val_keep_sequences = set(common_sequences_list[half_point:])\n",
    "\n",
    "test_df = test_df[~test_df['modified_sequence'].isin(val_keep_sequences)]\n",
    "val_df = val_df[~val_df['modified_sequence'].isin(test_keep_sequences)]\n",
    "print(f\"test dataset size: {len(test_df)}\")\n",
    "print(f\"validation dataset size: {len(val_df)}\")\n",
    "test_sequences = set(test_df[\"modified_sequence\"].unique())\n",
    "val_sequences = set(val_df[\"modified_sequence\"].unique())\n",
    "test_val_sequences = test_sequences | val_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d58a299-8bf5-4f4d-8259-f0e42fbbd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['dataset'].isin(train_datasets)]\n",
    "train_df = train_df[~train_df['modified_sequence'].isin(test_val_sequences)]\n",
    "train_sequences = set(train_df[\"modified_sequence\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6610c113-2f81-44d6-b2a7-5245d08f1353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sequence overlap between the sets\n"
     ]
    }
   ],
   "source": [
    "if not (test_sequences & val_sequences or test_sequences & train_sequences or val_sequences & train_sequences):\n",
    "    print(\"No sequence overlap between the sets\")\n",
    "else:\n",
    "    print(\"There is an overlap in sequences between the sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "667e5887-b20d-4eba-a198-1fe263f75d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index.to_series().to_csv(f\"{DATA}/train.csv\", index=False,header=False)\n",
    "test_df.index.to_series().to_csv(f\"{DATA}/test.csv\", index=False,header=False)\n",
    "val_df.index.to_series().to_csv(f\"{DATA}/val.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df086ac-ba8a-4816-9214-7f0fd3715799",
   "metadata": {},
   "source": [
    "## MSV000080814 train indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "595ed391-aebc-4109-84b4-f05a873aaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "train_df = apply_index_file(df,f\"{DATA}train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6832f0b5-6d23-4860-b450-1b38f3e5a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSV80814_indices = train_df[train_df['dataset']==\"MSV000080814\"].index.to_series()\n",
    "MSV80814_indices.to_csv(f'{TRAIN}MSV000080814.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96751d39-45f8-4e03-b728-207b21b28110",
   "metadata": {},
   "source": [
    "## increasing train indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01aae2d4-3180-4244-b12d-91ec8296be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "train_df = apply_index_file(df,f\"{DATA}train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d271fca2-930e-4d54-97c4-00b01fb881ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filenames = train_df['filename'].unique()\n",
    "total_files = len(unique_filenames)\n",
    "step_size = int(total_files * 0.1)  # Calculate 10% of total files\n",
    "\n",
    "# Create steps at 10% increments up to 90%\n",
    "steps = []\n",
    "for i in range(1, 10):  # 10%, 20%, 30%, ... 90% (stopping before 100%)\n",
    "    steps.append(i * step_size)\n",
    "\n",
    "# Add 100% as the final step\n",
    "steps.append(total_files)\n",
    "for x in steps:\n",
    "    subset = unique_filenames[:x]\n",
    "    train_df[train_df['filename'].isin(subset)].index.to_series().to_csv(\n",
    "        f'{TRAIN}runs_{x}.csv', index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd648ee9-1ca2-495a-8010-f86a407f4a62",
   "metadata": {},
   "source": [
    "## Small test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02bae1c8-f0dc-4972-a4a8-60a8c832aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "df_test = df.head(200)\n",
    "df_test.loc[0, 'filename'] = 'x'\n",
    "df_test.loc[1, 'filename'] = 'y'\n",
    "df_test.loc[2, 'filename'] = 'z'\n",
    "train = pd.Series(range(0, 100))     \n",
    "val = pd.Series(range(100, 150))  \n",
    "test = pd.Series(range(150, 200))   \n",
    "# Save each to a CSV\n",
    "train.to_csv(f\"{TEST}train.csv\", index=False, header=False)\n",
    "val.to_csv(f\"{TEST}val.csv\", index=False, header=False)\n",
    "test.to_csv(f\"{TEST}test.csv\", index=False, header=False)\n",
    "df_test.to_parquet(f\"{TEST}dataset.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mtl-pep-prop)",
   "language": "python",
   "name": "mtl-pep-prop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
