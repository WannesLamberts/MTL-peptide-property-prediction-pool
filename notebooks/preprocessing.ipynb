{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Adds 'src' to the module search path\n",
    "sys.path.append(os.path.abspath(\"../src\"))  # Adds 'src' to the module search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e1a72a-3eb9-469c-8791-38d6dcacd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import create_model_dataset\n",
    "from read_data import apply_index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9d8c432-728e-4443-868f-bc4b32419149",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tqdm.pandas()\n",
    "RAW_DATASET = \"../raw_data/massive.parquet\"\n",
    "DATA = \"../data/\"\n",
    "TRAIN = \"../data/train_subsets/\"\n",
    "TEST = \"../data/test/\"\n",
    "os.makedirs(DATA, exist_ok=True)\n",
    "os.makedirs(TRAIN, exist_ok=True)\n",
    "os.makedirs(TEST, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b53617-3a20-479e-9a05-2df1472cd549",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fa5156-9ab9-45dc-b92f-ec56ff927e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(RAW_DATASET,engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32135580-67f5-4130-b2c7-678d460cd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_keep_median(df):\n",
    "    \"\"\"\n",
    "    Ultra-optimized version for very large datasets (27M+ rows).\n",
    "    Uses vectorized operations throughout for maximum performance.\n",
    "    \"\"\"\n",
    "    print(\"calculating medians\")\n",
    "    group_medians = df.groupby(['modified_sequence', 'filename'])['label'].transform('median')\n",
    "    # Calculate absolute difference from median (vectorized)\n",
    "    abs_diff = (df['label'] - group_medians).abs()\n",
    "    \n",
    "    print(\"Getting groups\")\n",
    "    group_ids = df.groupby(['modified_sequence', 'filename']).ngroup()\n",
    "    \n",
    "\n",
    "    print(\"min ids\")\n",
    "    min_idx_per_group = pd.DataFrame({\n",
    "        'group_id': group_ids,\n",
    "        'abs_diff': abs_diff,\n",
    "        'original_idx': df.index\n",
    "    }).groupby('group_id')['abs_diff'].idxmin()\n",
    "\n",
    "    print(\"select indices\")\n",
    "    selected_indices = df.index[min_idx_per_group]\n",
    "    \n",
    "    return df.loc[selected_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d7dd55-a1fb-4f32-8d66-8a2deec537d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating medians\n",
      "Getting groups\n",
      "min ids\n",
      "select indices\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed = remove_duplicates_keep_median(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd2ccd2-def0-467a-89ad-169b6d6cd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_parquet(f\"{DATA}dataset_preprocessed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "261141fb-7f9e-4fdb-9b38-a27043120ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modified_sequence</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAAAG</td>\n",
       "      <td>77.383600</td>\n",
       "      <td>Bibo_20130621_CHS_IEF_3-10linear_24slices_08.m...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAAAG</td>\n",
       "      <td>93.708580</td>\n",
       "      <td>Bibo_20130621_CHS_IEF_3-10linear_24slices_15.m...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAAAG</td>\n",
       "      <td>89.782983</td>\n",
       "      <td>Bibo_20130621_CHS_IEF_3-10linear_24slices_16.m...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAAAG</td>\n",
       "      <td>85.309409</td>\n",
       "      <td>Bibo_20130621_CHS_IEF_3-10linear_24slices_18.m...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAAAG</td>\n",
       "      <td>99.475931</td>\n",
       "      <td>Bibo_20130621_CHS_IEF_3-10linear_24slices_20.m...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236451</th>\n",
       "      <td>YYYYWHLR</td>\n",
       "      <td>45.123521</td>\n",
       "      <td>20130502_EXQ6_SaDe_SA_76_05.mzML</td>\n",
       "      <td>MSV000080813</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236452</th>\n",
       "      <td>YYYYWHLRK</td>\n",
       "      <td>126.525771</td>\n",
       "      <td>20110715_EXQ1_TaGe_SA_PC11_6.mzXML</td>\n",
       "      <td>MSV000080069</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236453</th>\n",
       "      <td>YYYYWHLRK</td>\n",
       "      <td>78.161016</td>\n",
       "      <td>Bibo_20130110_CHS_IEF100_20121129_3-10linear_S...</td>\n",
       "      <td>MSV000080274</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236454</th>\n",
       "      <td>YYYYWHLRK</td>\n",
       "      <td>80.638047</td>\n",
       "      <td>HUVEC_ne_con_5a_1.mzXML</td>\n",
       "      <td>MSV000080225</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236455</th>\n",
       "      <td>YYYYWHLRKQVLHSQCVLREE</td>\n",
       "      <td>99.774503</td>\n",
       "      <td>140709_04_Orbi2_SK_CO_G240_T1275_6C2_4.mzXML</td>\n",
       "      <td>MSV000080276</td>\n",
       "      <td>iRT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27236456 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              modified_sequence       label   \n",
       "0             AAAAAAAAAAAAAAAAG   77.383600  \\\n",
       "1             AAAAAAAAAAAAAAAAG   93.708580   \n",
       "2             AAAAAAAAAAAAAAAAG   89.782983   \n",
       "3             AAAAAAAAAAAAAAAAG   85.309409   \n",
       "4             AAAAAAAAAAAAAAAAG   99.475931   \n",
       "...                         ...         ...   \n",
       "27236451               YYYYWHLR   45.123521   \n",
       "27236452              YYYYWHLRK  126.525771   \n",
       "27236453              YYYYWHLRK   78.161016   \n",
       "27236454              YYYYWHLRK   80.638047   \n",
       "27236455  YYYYWHLRKQVLHSQCVLREE   99.774503   \n",
       "\n",
       "                                                   filename       dataset task  \n",
       "0         Bibo_20130621_CHS_IEF_3-10linear_24slices_08.m...  MSV000080274  iRT  \n",
       "1         Bibo_20130621_CHS_IEF_3-10linear_24slices_15.m...  MSV000080274  iRT  \n",
       "2         Bibo_20130621_CHS_IEF_3-10linear_24slices_16.m...  MSV000080274  iRT  \n",
       "3         Bibo_20130621_CHS_IEF_3-10linear_24slices_18.m...  MSV000080274  iRT  \n",
       "4         Bibo_20130621_CHS_IEF_3-10linear_24slices_20.m...  MSV000080274  iRT  \n",
       "...                                                     ...           ...  ...  \n",
       "27236451                   20130502_EXQ6_SaDe_SA_76_05.mzML  MSV000080813  iRT  \n",
       "27236452                 20110715_EXQ1_TaGe_SA_PC11_6.mzXML  MSV000080069  iRT  \n",
       "27236453  Bibo_20130110_CHS_IEF100_20121129_3-10linear_S...  MSV000080274  iRT  \n",
       "27236454                            HUVEC_ne_con_5a_1.mzXML  MSV000080225  iRT  \n",
       "27236455       140709_04_Orbi2_SK_CO_G240_T1275_6C2_4.mzXML  MSV000080276  iRT  \n",
       "\n",
       "[27236456 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fd43e-27ab-4f05-a75b-ca5b7ed8be9b",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98ce4a8b-a098-46fd-8394-e3ec15c8350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "006c5f0d-5f5c-47b7-9dc9-8d0014c68b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dataset = df.groupby('dataset')['modified_sequence'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7815be13-ad1f-4bb9-a1b7-99bbe747b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = df['dataset'].unique()\n",
    "test_datasets = ['MSV000080274']\n",
    "val_datasets = ['MSV000079550']\n",
    "train_datasets = [d for d in all_datasets if d not in test_datasets + val_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c57933ac-f3a5-468a-99a4-9aac12579b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['dataset'].isin(test_datasets)].sample(350000, random_state=42) \n",
    "val_df = df[df['dataset'].isin(val_datasets)].sample(350000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a848c00-e3ff-469b-aa86-423411156036",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_with_intersection = set(test_df['modified_sequence'])\n",
    "val_sequences_with_intersection = set(val_df['modified_sequence'])\n",
    "common_sequences = test_sequences_with_intersection.intersection(val_sequences_with_intersection)\n",
    "common_sequences_list = list(common_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e4a5b18-fc9c-4516-9609-57253983c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset size: 247344\n",
      "validation dataset size: 249607\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(common_sequences_list)\n",
    "half_point = len(common_sequences_list) // 2\n",
    "test_keep_sequences = set(common_sequences_list[:half_point])\n",
    "val_keep_sequences = set(common_sequences_list[half_point:])\n",
    "\n",
    "test_df = test_df[~test_df['modified_sequence'].isin(val_keep_sequences)]\n",
    "val_df = val_df[~val_df['modified_sequence'].isin(test_keep_sequences)]\n",
    "print(f\"test dataset size: {len(test_df)}\")\n",
    "print(f\"validation dataset size: {len(val_df)}\")\n",
    "test_sequences = set(test_df[\"modified_sequence\"].unique())\n",
    "val_sequences = set(val_df[\"modified_sequence\"].unique())\n",
    "test_val_sequences = test_sequences | val_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d58a299-8bf5-4f4d-8259-f0e42fbbd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['dataset'].isin(train_datasets)]\n",
    "train_df = train_df[~train_df['modified_sequence'].isin(test_val_sequences)]\n",
    "train_sequences = set(train_df[\"modified_sequence\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6610c113-2f81-44d6-b2a7-5245d08f1353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sequence overlap between the sets\n"
     ]
    }
   ],
   "source": [
    "if not (test_sequences & val_sequences or test_sequences & train_sequences or val_sequences & train_sequences):\n",
    "    print(\"No sequence overlap between the sets\")\n",
    "else:\n",
    "    print(\"There is an overlap in sequences between the sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "667e5887-b20d-4eba-a198-1fe263f75d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index.to_series().to_csv(f\"{DATA}/train.csv\", index=False,header=False)\n",
    "test_df.index.to_series().to_csv(f\"{DATA}/test.csv\", index=False,header=False)\n",
    "val_df.index.to_series().to_csv(f\"{DATA}/val.csv\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df086ac-ba8a-4816-9214-7f0fd3715799",
   "metadata": {},
   "source": [
    "## MSV000080814 train indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "595ed391-aebc-4109-84b4-f05a873aaa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "train_df = apply_index_file(df,f\"{DATA}train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6832f0b5-6d23-4860-b450-1b38f3e5a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSV80814_indices = train_df[train_df['dataset']==\"MSV000080814\"].index.to_series()\n",
    "MSV80814_indices.to_csv(f'{TRAIN}MSV000080814.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96751d39-45f8-4e03-b728-207b21b28110",
   "metadata": {},
   "source": [
    "## increasing train indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01aae2d4-3180-4244-b12d-91ec8296be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "train_df = apply_index_file(df,f\"{DATA}train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d271fca2-930e-4d54-97c4-00b01fb881ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filenames = train_df['filename'].unique()\n",
    "total_files = len(unique_filenames)\n",
    "step_size = int(total_files * 0.1)  # Calculate 10% of total files\n",
    "\n",
    "# Create steps at 10% increments up to 90%\n",
    "steps = []\n",
    "for i in range(1, 10):  # 10%, 20%, 30%, ... 90% (stopping before 100%)\n",
    "    steps.append(i * step_size)\n",
    "\n",
    "# Add 100% as the final step\n",
    "steps.append(total_files)\n",
    "for x in steps:\n",
    "    subset = unique_filenames[:x]\n",
    "    train_df[train_df['filename'].isin(subset)].index.to_series().to_csv(\n",
    "        f'{TRAIN}runs_{x}.csv', index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd648ee9-1ca2-495a-8010-f86a407f4a62",
   "metadata": {},
   "source": [
    "## Small test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02bae1c8-f0dc-4972-a4a8-60a8c832aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA}dataset.parquet\",engine=\"pyarrow\")\n",
    "df_test = df.head(200)\n",
    "df_test.loc[0, 'filename'] = 'x'\n",
    "df_test.loc[1, 'filename'] = 'y'\n",
    "df_test.loc[2, 'filename'] = 'z'\n",
    "train = pd.Series(range(0, 100))     \n",
    "val = pd.Series(range(100, 150))  \n",
    "test = pd.Series(range(150, 200))   \n",
    "# Save each to a CSV\n",
    "train.to_csv(f\"{TEST}train.csv\", index=False, header=False)\n",
    "val.to_csv(f\"{TEST}val.csv\", index=False, header=False)\n",
    "test.to_csv(f\"{TEST}test.csv\", index=False, header=False)\n",
    "df_test.to_parquet(f\"{TEST}dataset.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mtl-pep-prop)",
   "language": "python",
   "name": "mtl-pep-prop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
