{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69717a6c-e24b-48ea-b797-65227c17ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Adds 'src' to the module search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a3af79-3f9e-4028-96ba-80e5d9c0c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f34ca3-6872-41f4-bb12-436b0e998622",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9b63eaac-ba87-4cd1-8036-e29ed4628ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "RAW_DATA = \"../raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6e63388c-84e6-4853-beba-fbd4ec513b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{RAW_DATA}80_tasks.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = df['dataset'].unique()\n",
    "test_datasets = ['MSV000080274']\n",
    "val_datasets = ['MSV000079550']\n",
    "train_datasets = [d for d in all_datasets if d not in test_datasets + val_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cdd741f5-acb3-4507-bbb6-cca0535a2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['dataset'].isin(test_datasets)].sample(350000, random_state=42) \n",
    "val_df = df[df['dataset'].isin(val_datasets)].sample(350000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "05df4b1c-7d5f-463c-9350-905c9b9dda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_with_intersection = set(test_df['sequence'])\n",
    "val_sequences_with_intersection = set(val_df['sequence'])\n",
    "common_sequences = test_sequences_with_intersection.intersection(val_sequences_with_intersection)\n",
    "common_sequences_list = list(common_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9240eaf4-070f-477a-96a1-a89ad00f6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(common_sequences_list)\n",
    "half_point = len(common_sequences_list) // 2\n",
    "test_keep_sequences = set(common_sequences_list[:half_point])\n",
    "val_keep_sequences = set(common_sequences_list[half_point:])\n",
    "\n",
    "test_df = test_df[~test_df['sequence'].isin(val_keep_sequences)]\n",
    "val_df = val_df[~val_df['sequence'].isin(test_keep_sequences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cd0a617e-c673-427d-b256-f6dd78fe5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned test dataset size: 240299\n",
      "Cleaned validation dataset size: 249888\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cleaned test dataset size: {len(test_df)}\")\n",
    "print(f\"Cleaned validation dataset size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "93685e83-a98a-4353-96da-fabeb10ca334",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = set(test_df[\"sequence\"].unique())\n",
    "val_sequences = set(val_df[\"sequence\"].unique())\n",
    "test_val_sequences = test_sequences | val_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "becee473-621b-4574-9bb2-a4a364d4f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['dataset'].isin(train_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "097e79ac-4cad-4cbd-906b-8da774976b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['sequence'].isin(test_val_sequences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bf8329e9-b796-4713-b043-b70aee63da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = set(train_df[\"sequence\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3f9415b4-9855-4313-809b-499ff08efdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sequence overlap between the sets\n"
     ]
    }
   ],
   "source": [
    "if not (test_sequences & val_sequences or test_sequences & train_sequences or val_sequences & train_sequences):\n",
    "    print(\"No sequence overlap between the sets\")\n",
    "else:\n",
    "    print(\"There is an overlap in sequences between the sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a8ea9e0c-75e7-4691-9a4d-460e944f6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/parquet/\"\n",
    "test_df.to_parquet(f\"{out_dir}test.parquet\", index=False)\n",
    "val_df.to_parquet(f\"{out_dir}val.parquet\", index=False)\n",
    "train_df.to_parquet(f\"{out_dir}train.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc3491-0bbf-4621-b475-e04a00a418c6",
   "metadata": {},
   "source": [
    "## Train two datasets comparison split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d193acea-bdc4-4c24-88e9-cabda0768136",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILES = \"../data/parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "07633f41-ebc3-4a58-87a9-198a16040c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(f\"{PARQUET_FILES}train.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8fc820ce-0f08-4d03-ab19-8188bad47443",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = train_df[\"dataset\"].unique()\n",
    "low_variety_datasets = [\"MSV000080814\"]\n",
    "high_variety_datasets = [d for d in all_datasets if d not in low_variety_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0485af0b-081a-4ab0-b612-bbce7369cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_variety_df = train_df[train_df['dataset'].isin(low_variety_datasets)]\n",
    "high_variety_df = train_df[train_df['dataset'].isin(high_variety_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e79fb853-3b70-48cd-a9d1-4f036b736464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low variety df size is: 1476825\n",
      "high variety df size is: 4427698\n",
      "Ratio is: 0.3335423960712768\n"
     ]
    }
   ],
   "source": [
    "low_len = len(low_variety_df)\n",
    "high_len = len(high_variety_df)\n",
    "ratio = low_len / high_len\n",
    "print(f\"low variety df size is: {low_len}\")\n",
    "print(f\"high variety df size is: {high_len}\")\n",
    "print(f\"Ratio is: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "37028c40-b62e-49a7-bacb-689ee97ddede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lambe\\AppData\\Local\\Temp\\ipykernel_33724\\1504092114.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  high_variety_df = high_variety_df.groupby('filename').apply(lambda x: x.sample(frac=ratio, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "high_variety_df = high_variety_df.groupby('filename').apply(lambda x: x.sample(frac=ratio, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cb4d4cd1-8d0f-43bc-aa7b-56083854243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/parquet/\"\n",
    "low_variety_df.to_parquet(f\"{out_dir}train_low_variety.parquet\", index=False)\n",
    "high_variety_df.to_parquet(f\"{out_dir}train_high_variety.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec7935-c656-4c77-a21f-2d9718c0bf07",
   "metadata": {},
   "source": [
    "# Pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3fb0814-0667-47f9-a8be-35be448d38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46ea82b5-6716-46f9-8369-dc3d5fa92dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILES = \"../data/parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bf9a935-7996-4cd4-a046-32cbb425e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(f\"{PARQUET_FILES}val.parquet\",\"../data/all_data_validation.csv\")\n",
    "create_dataset(f\"{PARQUET_FILES}test.parquet\",\"../data/all_data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb7f62-81c3-4e44-856f-c156e1c2f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_df =  pd.read_parquet(f\"{PARQUET_FILES}val.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27600136-5f98-4cbd-bb93-58699f0f9b0e",
   "metadata": {},
   "source": [
    "## two datasets comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5236e41e-0861-4293-9654-20388034b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_data import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ff1320-6f4f-4988-8660-cd9f93a0d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILES = \"../data/parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95492318-97d6-4a6e-be78-92c0dcec8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_variety_df =  pd.read_parquet(f\"{PARQUET_FILES}train_low_variety.parquet\",engine=\"pyarrow\")\n",
    "high_variety_df =  pd.read_parquet(f\"{PARQUET_FILES}train_high_variety.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4461718b-c8a7-4016-8b7f-51837f9a3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(f\"{PARQUET_FILES}train_low_variety.parquet\",\"../data/low_variety/all_data.csv\")\n",
    "create_dataset(f\"{PARQUET_FILES}train_high_variety.parquet\",\"../data/high_variety/all_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
