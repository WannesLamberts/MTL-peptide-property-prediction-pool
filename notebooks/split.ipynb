{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69717a6c-e24b-48ea-b797-65227c17ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))  # Adds 'src' to the module search path\n",
    "sys.path.append(os.path.abspath(\"../src\"))  # Adds 'src' to the module search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a3af79-3f9e-4028-96ba-80e5d9c0c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils_data import create_dataset,create_dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f34ca3-6872-41f4-bb12-436b0e998622",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b63eaac-ba87-4cd1-8036-e29ed4628ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "RAW_DATA = \"../raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e63388c-84e6-4853-beba-fbd4ec513b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{RAW_DATA}80_tasks.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = df['dataset'].unique()\n",
    "test_datasets = ['MSV000080274']\n",
    "val_datasets = ['MSV000079550']\n",
    "train_datasets = [d for d in all_datasets if d not in test_datasets + val_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd741f5-acb3-4507-bbb6-cca0535a2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['dataset'].isin(test_datasets)].sample(350000, random_state=42) \n",
    "val_df = df[df['dataset'].isin(val_datasets)].sample(350000, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05df4b1c-7d5f-463c-9350-905c9b9dda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences_with_intersection = set(test_df['sequence'])\n",
    "val_sequences_with_intersection = set(val_df['sequence'])\n",
    "common_sequences = test_sequences_with_intersection.intersection(val_sequences_with_intersection)\n",
    "common_sequences_list = list(common_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9240eaf4-070f-477a-96a1-a89ad00f6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(common_sequences_list)\n",
    "half_point = len(common_sequences_list) // 2\n",
    "test_keep_sequences = set(common_sequences_list[:half_point])\n",
    "val_keep_sequences = set(common_sequences_list[half_point:])\n",
    "\n",
    "test_df = test_df[~test_df['sequence'].isin(val_keep_sequences)]\n",
    "val_df = val_df[~val_df['sequence'].isin(test_keep_sequences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0a617e-c673-427d-b256-f6dd78fe5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned test dataset size: 241493\n",
      "Cleaned validation dataset size: 250742\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cleaned test dataset size: {len(test_df)}\")\n",
    "print(f\"Cleaned validation dataset size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93685e83-a98a-4353-96da-fabeb10ca334",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = set(test_df[\"sequence\"].unique())\n",
    "val_sequences = set(val_df[\"sequence\"].unique())\n",
    "test_val_sequences = test_sequences | val_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "becee473-621b-4574-9bb2-a4a364d4f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['dataset'].isin(train_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097e79ac-4cad-4cbd-906b-8da774976b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['sequence'].isin(test_val_sequences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8329e9-b796-4713-b043-b70aee63da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = set(train_df[\"sequence\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f9415b4-9855-4313-809b-499ff08efdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sequence overlap between the sets\n"
     ]
    }
   ],
   "source": [
    "if not (test_sequences & val_sequences or test_sequences & train_sequences or val_sequences & train_sequences):\n",
    "    print(\"No sequence overlap between the sets\")\n",
    "else:\n",
    "    print(\"There is an overlap in sequences between the sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be96e113-c8dd-42b1-a380-04e9a80597fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38cb51b-3e84-4ba1-a91d-61de7648e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_df(val_df,f\"{out_dir}val.parquet\")\n",
    "create_dataset_df(test_df,f\"{out_dir}test.parquet\")\n",
    "create_dataset_df(train_df,f\"{out_dir}train.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906523a-38cd-42ff-899f-3c736abb13e8",
   "metadata": {},
   "source": [
    "## increasing train data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "065fa96e-435a-4216-85aa-ff6a784eac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05bbe4e8-02fb-4081-93a5-04adecc25f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(f\"{DATA}train.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "422bc3da-b091-49e3-80d4-4feb253c8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"../data/increasing_data/\"\n",
    "os.makedirs(output, exist_ok=True)\n",
    "unique_filenames = train_df['filename'].unique()\n",
    "subsets=[]\n",
    "for x in range(150,len(unique_filenames),150):\n",
    "    subset = unique_filenames[:x]\n",
    "    train_df[train_df['filename'].isin(subset)].index.to_series().to_csv(f'{output}train_indices_{x}.csv', index=False,header=False)\n",
    "subset = unique_filenames[0:len(unique_filenames)]\n",
    "train_df[train_df['filename'].isin(subset)].index.to_series().to_csv(f'{output}train_indices_{len(unique_filenames)}.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939f2f6-e3b1-4839-ae30-ab3ddea1c798",
   "metadata": {},
   "source": [
    "### Small test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5482098-d40a-42d3-b9fa-d3cbaf41ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(f\"{DATA}train.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee04a4f-8a01-49bb-bece-d6965fb3b91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\data\\increasing_data_small'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      5\u001b[0m     subset \u001b[38;5;241m=\u001b[39m unique_filenames[:x]\n\u001b[1;32m----> 6\u001b[0m     train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(subset)]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtrain_indices_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '..\\data\\increasing_data_small'"
     ]
    }
   ],
   "source": [
    "output = \"../data/increasing_data_small/\"\n",
    "unique_filenames = train_df['filename'].unique()\n",
    "subsets=[]\n",
    "for x in range(1,6,1):\n",
    "    subset = unique_filenames[:x]\n",
    "    train_df[train_df['filename'].isin(subset)].index.to_series().to_csv(f'{output}train_indices_{x}.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc3491-0bbf-4621-b475-e04a00a418c6",
   "metadata": {},
   "source": [
    "## Train two datasets comparison split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193acea-bdc4-4c24-88e9-cabda0768136",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07633f41-ebc3-4a58-87a9-198a16040c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(f\"{DATA}train.parquet\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc820ce-0f08-4d03-ab19-8188bad47443",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = train_df[\"dataset\"].unique()\n",
    "low_variety_datasets = [\"MSV000080814\"]\n",
    "high_variety_datasets = [d for d in all_datasets if d not in low_variety_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485af0b-081a-4ab0-b612-bbce7369cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_variety_df = train_df[train_df['dataset'].isin(low_variety_datasets)]\n",
    "high_variety_df = train_df[train_df['dataset'].isin(high_variety_datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fb853-3b70-48cd-a9d1-4f036b736464",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_len = len(low_variety_df)\n",
    "high_len = len(high_variety_df)\n",
    "ratio = low_len / high_len\n",
    "print(f\"low variety df size is: {low_len}\")\n",
    "print(f\"high variety df size is: {high_len}\")\n",
    "print(f\"Ratio is: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37028c40-b62e-49a7-bacb-689ee97ddede",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_variety_df = high_variety_df.groupby('filename').apply(lambda x: x.sample(frac=ratio, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d4cd1-8d0f-43bc-aa7b-56083854243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/\"\n",
    "os.makedirs(f\"{out_dir}/low_variety/\", exist_ok=True)\n",
    "os.makedirs(f\"{out_dir}/high_variety/\", exist_ok=True)\n",
    "\n",
    "low_variety_df.to_parquet(f\"{out_dir}low_variety/all.parquet\", index=False)\n",
    "high_variety_df.to_parquet(f\"{out_dir}high_variety/all.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec7935-c656-4c77-a21f-2d9718c0bf07",
   "metadata": {},
   "source": [
    "# Pre process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
